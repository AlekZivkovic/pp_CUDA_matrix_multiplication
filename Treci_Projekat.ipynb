{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Treci Projekat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlekZivkovic/pp_CUDA_matrix_multiplication/blob/main/Treci_Projekat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyCuda"
      ],
      "metadata": {
        "id": "EE81be-Bv1iN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-yAK9ESVtN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d9b260-28ca-4780-d08c-84eefd8116f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2021.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "  Downloading pytools-2021.2.9.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2021.1-cp37-cp37m-linux_x86_64.whl size=626633 sha256=8a635e9bd735c07076b904f727980b11c74812127fe727391f328dc61dee8946\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/ef/49/dc6a5feb8d980b37c83d465ecab24949a6aa19458522a9e001\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2021.2.9-py2.py3-none-any.whl size=62370 sha256=f18cf3f5ece2a73af8f3c4fa10f20e38b0701a826ac32e9ba11a6ddb1b91b74a\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/b9/6e/94bb014f6484b15ec77e7877f3a227609481ffd98db364504d\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.1.6 pycuda-2021.1 pytools-2021.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldX0az8vwmXQ",
        "outputId": "0328fec8-761f-4f54-d25d-4e24c92dafb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 13 15:58:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cuda Funkcije"
      ],
      "metadata": {
        "id": "Nwo1B31gw3p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "#include <stdio.h>\n",
        "\n",
        "    //Trazi trenutni element iz a i b i vraca njihov proizvod\n",
        "    //Koristim za svaki element reda iz matrice A i kolone iz matrice B\n",
        "    __device__ float find_in_a_and_b(int transa, int transb, int n_a, int n_b, float* A, float* B, int i){\n",
        "\n",
        "        int index_a, index_b, x_a, y_a, x_b, y_b;\n",
        "        \n",
        "        //Trazim trenutni element iz matrice a\n",
        "        //Ako nije transponovana idem po redu, a ako jeste po koloni y (y jer je to red trenutnog polja matrice c, treba da idem po tom redu, odnosno koloni, matrice a)\n",
        "        \n",
        "        //Ako matrica a nije transponovana zakucam red i pomeram se po njemu u odnosu na trenutno mesto koje gledam(i), a ako jeste zakucam kolonu i pomeram se po njoj\n",
        "        //Na kraju uzmem index u matrici a (trenutni red * velicina tog red(broj kolona) + trenuna kolona)\n",
        "        //Zakucavam red ili kolonu po tome u kojem se redu nalazi trenutna nit\n",
        "        if(!transa){\n",
        "            x_a = i;\n",
        "            y_a = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "        }\n",
        "        else{\n",
        "            y_a = i;\n",
        "            x_a = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "        }\n",
        "        index_a = y_a*n_a + x_a;\n",
        "\n",
        "        //Ista logika kao za matricu a, samo sto zakucavam kolonu ili red u odnosu na kolonu u kojoj se nalazi trenutna nit\n",
        "        if(!transb){\n",
        "            y_b = i;\n",
        "            x_b = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "        }\n",
        "        else{\n",
        "            x_b = i;\n",
        "            y_b = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "        }\n",
        "        index_b = y_b*n_b + x_b;\n",
        "\n",
        "        //Vracam proizvod elementa iz matrice a i elementa iz matrice b\n",
        "        return A[index_a] * B[index_b];\n",
        "    }\n",
        "\n",
        "    //transa: [1] - transponovana je, [0] - nije transponovana\n",
        "    __global__ void gemm_no_shared(int transa, int transb, int m_a, int n_a, int k, float alpha, float* A, float* B, float* C){\n",
        "        \n",
        "        __shared__ int m_c, n_c, m_b, n_b;\n",
        "        \n",
        "        //Uzimam velicine b i c matrice, cisto da bi mi bilo lakse, ubacujem to u shared memoriju da ne bi svaki thread morao da racuna za sebe, prvi thread u bloku izracuna dimenzije\n",
        "        //Nakon sto prvi thread izracuna dimenzije, syncujem niti da bi svaka nit imala pristup dimenzijama\n",
        "        if(threadIdx.x == 0 && threadIdx.y == 0){\n",
        "            //Gledam na sta se odnosi k\n",
        "            if(!transb)\n",
        "                n_b = k;\n",
        "            else\n",
        "                m_b = k;\n",
        "            \n",
        "            //Gledam drugu dimenziju matrice b, odnosno unutrasnju vrednost koja se poklapa sa nekom od dimenzija matrice a\n",
        "            if(!transa && !transb)\n",
        "                m_b = n_a;\n",
        "            else if(transa && !transb)\n",
        "                m_b = m_a;\n",
        "            else if(!transa && transb)\n",
        "                n_b = n_a;\n",
        "            else\n",
        "                n_b = m_a;\n",
        "\n",
        "            //Po dimenzijama matrica a i b racunam dimenzije matrice c\n",
        "            m_c = (transa == 1)? n_a: m_a;\n",
        "            n_c = (transb == 1)? m_b: n_b;\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        //Uzimam x i y koordinatu trenutnog threada, odnosno trenutnog polja matrice c, ako ispadam iz matrice radim return\n",
        "        int x = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "        int y = blockDim.y*blockIdx.y + threadIdx.y;\n",
        "        \n",
        "        if(x >= n_c || y >= m_c)\n",
        "            return;\n",
        "        \n",
        "        int index_c = y*n_c + x;\n",
        "        \n",
        "        //Uzimam unutrasnju vrednost kao limit, pokazuje mi koliko elemenata treba da gledam za trenutno polje, odnosno koliko elemenata iz matrica a i b treba da pomnozim\n",
        "        int limit = (transa == 0)? n_a: m_a;\n",
        "        float sum = 0;\n",
        "        //Prolazim kroz red matrice a i kolonu matrice b i u svakoj iteraciji dodajem na sumu proizvod trenutnih elemenata matrica\n",
        "        for(int i = 0; i<limit; i++){\n",
        "            sum += find_in_a_and_b(transa, transb, n_a, n_b, A, B, i);\n",
        "        }\n",
        "        C[index_c] = sum*alpha;\n",
        "    }\n",
        "\n",
        "  //matTip: [0] - matrica a, [1] - matrica b\n",
        "  //block_offset - blok koji se trenutno gleda, odnosno blok koji se trenutno ubacuje u shared niz\n",
        "  //i_cord - red trenutnog threada, j_cord - kolona trenutnog threada\n",
        "  __device__ float get_valueV2(int matTip,int transflag, int colum_len,int row_len,int j_cord,int i_cord,int block_offset,float *matrix){\n",
        "\n",
        "       int idx;\n",
        "\n",
        "       //Uslovi u svakom ifu proveravaju da li vrednosti koja se gleda ispada iz matrice (da li je poslednji blok, i ako jeste da li bi trenutni thread iz c matrice postojao u tom bloku ili ne)\n",
        "\n",
        "       //Ako se gleda matrica a i nije transponovana, uzimamo vrednost iz trenutnog bloka, koji se pomera po redovima, koja se nalazi na poziciji trenutnog threada\n",
        "       if(matTip == 0 && transflag==0 && blockDim.x*block_offset + threadIdx.x < colum_len){\n",
        "          idx=i_cord * colum_len + (block_offset * blockDim.x + threadIdx.x);\n",
        "            return matrix[idx];\n",
        "       }\n",
        "\n",
        "       //Ako se gleda matrica a i transponovana je, uzimamo vrednost iz trenutnog bloka, koji se pomera po kolonama, koja se nalazi na poziciji trenutnog threada\n",
        "       if(matTip == 0 && transflag==1 && blockDim.x*block_offset + threadIdx.x < row_len){\n",
        "          idx= (block_offset * blockDim.y +threadIdx.x) * colum_len + i_cord;\n",
        "          return matrix[idx];\n",
        "       }\n",
        "\n",
        "      if(matTip==1 && transflag==0 && blockDim.x * block_offset + threadIdx.y < row_len){\n",
        "            \n",
        "            idx = ( block_offset * blockDim.y + threadIdx.y) * colum_len + j_cord; \n",
        "            return matrix[idx];           \n",
        "      }\n",
        "      \n",
        "      //Ukoliko imamo vise blokova moramo voditi racuna o tome da li nasa vrednost ispada iz matrice b,\n",
        "      //odnosno da li ispada iz reda koji se gleda\n",
        "      if(matTip == 1 && transflag==1 && block_offset * blockDim.x + threadIdx.y < colum_len){\n",
        "          idx=j_cord * colum_len + (block_offset * blockDim.y + threadIdx.y);\n",
        "          return matrix[idx];\n",
        "      }\n",
        "\n",
        "       return 0;\n",
        "    }\n",
        "\n",
        "    //Prvi deo funkcionise na isti nacin kao gemm_no_shared\n",
        "    __global__ void gemm_shared(int transa, int transb, int m_a, int n_a, int k, float alpha, float* A, float* B, float* C){\n",
        "        __shared__ int m_c, n_c, m_b, n_b;\n",
        "        //postavljamo odgovarajuce vrednosti granica nasih matrica\n",
        "        if(threadIdx.x == 0 && threadIdx.y == 0){\n",
        "            if(!transb)\n",
        "                n_b = k;\n",
        "            else\n",
        "                m_b = k;\n",
        "            \n",
        "            if(!transa && !transb)\n",
        "                m_b = n_a;\n",
        "            else if(transa && !transb)\n",
        "                m_b = m_a;\n",
        "            else if(!transa && transb)\n",
        "                n_b = n_a;\n",
        "            else\n",
        "                n_b = m_a;\n",
        "\n",
        "            m_c = (transa == 1)? n_a: m_a;\n",
        "            n_c = (transb == 1)? m_b: n_b;\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        //pronalazimo x_cord & y_cord za nit\n",
        "        int x = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "        int y = blockDim.y*blockIdx.y + threadIdx.y;\n",
        "       \n",
        "        //pronalazimo index za koji element nit radi\n",
        "        //n_c je br kolona elem sama sirina matrice\n",
        "        int index_c = y*n_c + x;\n",
        "\n",
        "        float sum = 0;\n",
        "\n",
        "        \n",
        "        int limit = (transa == 0)? n_a: m_a;\n",
        "        //Nizovi koji predtavljaju izvucene vrednosti iz matrice a i iz matrice b \n",
        "        __shared__ float a_spart[1024];\n",
        "        __shared__ float b_spart[1024];\n",
        "\n",
        "       // Pronalazimo ukupni broj blokova koji treba da se prodju po unutrasnjoj dimenziji matrica, posto je celobrojno deljenje moramo da zaokruzimo\n",
        "        int block_number= limit / blockDim.x; \n",
        "        //zaokruzujemo na vecu decimalu\n",
        "        block_number= limit % blockDim.x ? block_number + 1 : block_number;\n",
        "        \n",
        "        //Prolazicemo kroz sve blokove koji ce nam trebati za trenutni blok koj se izvrsava \n",
        "        //(ako smo u bloku 0,0 prolazicemo kroz sve blokove iz matrice a koje predstavljaju redove 0-32 i sve blokove koji predstavljaju kolone 0-32 u matrici b (razlikovace se u odnosu na to da li su transponovane))\n",
        "        //(ako smo u bloku 0, 1 sve redove koji su 0-32 i sve kolone koje su 33-64)\n",
        "        //Svaki thread ce da ubaci u shared niz element iz bloka koji se nalazi na istom mestu unutar tog bloka kao trenutni thread\n",
        "        for(int i=0; i < block_number ; i++){\n",
        "          // posto koristimo 1D niz svaka nit ce na svoje polje ubaciti odg vrednost iz glvne matrice\n",
        "          a_spart[threadIdx.y*blockDim.x + threadIdx.x]=0;\n",
        "          b_spart[threadIdx.y*blockDim.x + threadIdx.x]=0;\n",
        "        \n",
        "          //Posto get_value svakako gleda da li je matrica transponovana ili nije, indeksi se nece razlikovati (bilo da se u matrici a gledaju redovi ili kolone za mnozenje, u nizu se gleda kao da je red)\n",
        "          a_spart[threadIdx.y*blockDim.y + threadIdx.x] = get_valueV2(0,transa, n_a,m_a,x,y,i,A);\n",
        "        \n",
        "          b_spart[threadIdx.y*blockDim.x + threadIdx.x]= get_valueV2(1,transb, n_b,m_b,x,y,i,B);\n",
        "\n",
        "          //Threadovi cekaju da svaki ubaci vrednosti u a i b shared niz, sto ce znaciti da trenutno u a i b nizu imamo neki blok koji predstavlja deo redova i kolona koje treba da se pomnoze\n",
        "          __syncthreads(); \n",
        "          int idx_a,idx_b;\n",
        "          \n",
        "          //Posto su blokovi 32x32, svaki thread prolazi kroz 32 elementa koja predstavljaju deo elemenata reda matrice a i kolone matrice b koje trenutni thread treba da gleda, mnoze vrednosti koje treba\n",
        "          //i ubacuju sabiraju ih sa do tada izracunatim vrednostima\n",
        "          //Ako u trenutnoim blokovima ima manje vrednosti od dimenzije bloka (trenutni blok sadrzi samo 20 elemenata u jednom redu), shared niz za ostale redove ima 0, pa se zbir nece menjati \n",
        "          for(int j = 0; j < blockDim.y; j++){\n",
        "\n",
        "            idx_a= threadIdx.y * blockDim.x + j;\n",
        "            idx_b=j* blockDim.x + threadIdx.x ;\n",
        "            \n",
        "            sum  +=a_spart[idx_a] * b_spart[idx_b] ;\n",
        "          \n",
        "          }\n",
        "          __syncthreads();\n",
        "\n",
        "\n",
        "        }\n",
        "        \n",
        "        //Ako nismo ispali iz matrice c, suma se ubacuje na dobro mesto\n",
        "        if(x < n_c && y < m_c)\n",
        "          C[index_c] = sum*alpha;\n",
        "\n",
        "    }\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "AlQCx63ww7Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main deo koda"
      ],
      "metadata": {
        "id": "cRE1ap0iw73L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def main_func():\n",
        "    #m_a = int(input('Unesite broj redova matrice A: '))\n",
        "    #n_a = int(input('Unesite broj kolona matrice A: '))\n",
        "\n",
        "    #m_b = int(input(\"Unesite broj redova matrice B: \"))\n",
        "    #n_b = int(input(\"Unesite broj kolona matrice B: \"))\n",
        "\n",
        "    #trans_a = input('Unesite transA: ').lower()\n",
        "    #trans_b = input('Unesite transB: ').lower()\n",
        "    #alpha = int(input('Unesite alpha: '))\n",
        "    \n",
        "    #[m] - broj redova, [n] - broj kolona\n",
        "    #Matrica ce biti mxn\n",
        "    m_a=300\n",
        "    n_a=500\n",
        "    m_b=300\n",
        "    n_b=500\n",
        "    trans_a = 'n'\n",
        "    trans_b = 't'\n",
        "    alpha = 3\n",
        "\n",
        "    #Ako se unutrasnje dimenzije ne poklapaju izbacuje se greska\n",
        "    if (trans_a == 'n' and trans_b == 'n' and n_a != m_b) or (trans_a == 'n' and trans_b == 't' and n_a != n_b) or (trans_a == 't' and trans_b == 'n' and m_a != m_b) or (trans_a == 't' and trans_b == 't' and m_a != n_b):\n",
        "        print(\"Nisu dobre dimenzije\")\n",
        "        return;\n",
        "\n",
        "    #k - vrednost koja se razlikuje, u odnosu na to da li je b transponovano ili ne, uzima se krajnja desna dimenzija jer se unutrasnja dimenzija b poklapa sa unutrasnjom dimenzijom a\n",
        "    k = n_b if trans_b == 'n' else m_b\n",
        "    #Uzimam dimenzije matrice c u odnosu na to sta je transponovano, uzimam spoljasnje vrednosti\n",
        "    m_c = m_a if trans_a == 'n' else n_a\n",
        "    n_c = n_b if trans_b == 'n' else m_b\n",
        "    mat_c = np.zeros((m_c, n_c), dtype = np.float32)\n",
        "\n",
        "    mat_a = np.random.randn(m_a,n_a).astype(dtype=np.float32)\n",
        "    mat_a = np.round(mat_a, 1)\n",
        "    mat_b = np.random.randn(m_b,n_b).astype(dtype=np.float32)\n",
        "    mat_b = np.round(mat_b, 1)\n",
        "    print(np.matrix(mat_a))\n",
        "    print(np.matrix(mat_b))\n",
        "\n",
        "    func = mod.get_function(\"gemm_shared\")\n",
        "    \n",
        "    a_gpu = cuda.mem_alloc(mat_a.nbytes)\n",
        "    b_gpu = cuda.mem_alloc(mat_b.nbytes)\n",
        "    c_gpu = cuda.mem_alloc(mat_c.nbytes)\n",
        "\n",
        "    cuda.memcpy_htod(a_gpu, mat_a)\n",
        "    cuda.memcpy_htod(b_gpu, mat_b)\n",
        "    #Posto je teze da se posalje karakter funkciji, samo pravim 1 ili 0 kao true ili false, [1] - transponovano, [0] - nije trensponovano\n",
        "    trans_a_int = 1 if trans_a == 't' else 0\n",
        "    trans_b_int = 1 if trans_b == 't' else 0\n",
        "  \n",
        "\n",
        "    func(np.int32(trans_a_int), np.int32(trans_b_int), np.int32(m_a), np.int32(n_a), np.int32(k), np.float32(alpha), a_gpu, b_gpu, c_gpu, \n",
        "         block = (32,32, 1), grid = (math.ceil(mat_c.shape[1]/32), math.ceil(mat_c.shape[0]/32), 1))\n",
        "\n",
        "    #Ako je neka od matrica transponovana, transponujem je da bih mogao da uradim matmul kako treba\n",
        "    if trans_a == 't':\n",
        "        mat_a = np.transpose(mat_a)\n",
        "    if trans_b == 't':\n",
        "        mat_b = np.transpose(mat_b)\n",
        "    #print(np.matrix(mat_a))\n",
        "    #print(np.matrix(mat_b))\n",
        "    mul_mat = np.matmul(mat_a, mat_b)\n",
        "    mul_mat = mul_mat*alpha\n",
        "    mul_mat = np.round(mul_mat, 2)\n",
        "    print()\n",
        "    print(np.matrix(mul_mat))\n",
        "    print()\n",
        "\n",
        "    cuda.memcpy_dtoh(mat_c, c_gpu)\n",
        "    mat_c = np.round(mat_c, 2)\n",
        "    print(np.matrix(mat_c))\n",
        "    #Zna da izbaci false jer se desi da omasi u racunanju za neka random polja (za matrice 30x30 se desilo najvise 2 false)\n",
        "    print((mat_c == mul_mat).all())\n",
        "    #for i in range (m_c):\n",
        "     #   for j in range (n_c):\n",
        "      #      if(mat_c[i][j] != mul_mat[i][j]):\n",
        "       #         print(i, j)\n",
        "\n",
        "main_func()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtJ1zAASw-jj",
        "outputId": "e4fd28ef-3319-496c-dade-8a2c9b5b37a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.1  0.7 -1.8 ... -0.7 -0.5 -1.2]\n",
            " [ 0.2 -0.2 -0.3 ...  0.9 -1.9 -0.8]\n",
            " [ 0.4 -0.5 -1.7 ...  1.7  2.1 -1.4]\n",
            " ...\n",
            " [ 1.  -0.8  0.2 ... -0.  -2.   0.8]\n",
            " [-2.1  1.1 -0.1 ...  1.5 -0.9 -0.7]\n",
            " [ 0.9 -0.8  0.7 ... -1.5  0.6 -1.9]]\n",
            "[[ 0.6  0.5  1.  ...  1.4 -0.5  0.9]\n",
            " [ 0.2  0.7 -1.  ...  1.8  1.4 -0.4]\n",
            " [-0.3 -0.  -0.7 ... -0.4 -1.9 -0.6]\n",
            " ...\n",
            " [-0.4  0.6  1.8 ...  0.6 -0.5 -0.2]\n",
            " [-0.5  1.1  1.5 ... -1.6 -0.4  0.5]\n",
            " [-1.8 -1.1  0.2 ... -0.3  0.6 -0.9]]\n",
            "\n",
            "[[ -37.23    7.65  -70.35 ...   -8.22  -57.81  -58.47]\n",
            " [ -54.39  -36.39   67.41 ...   34.02  -40.8    49.44]\n",
            " [ 172.41   10.89  -56.58 ...  -96.66   10.35 -163.83]\n",
            " ...\n",
            " [  57.24  -19.68  112.17 ...  -16.5   -68.43   47.1 ]\n",
            " [-108.75    2.31  -37.53 ...  -29.97   65.16   41.7 ]\n",
            " [   9.     21.21   43.56 ...   -8.97  -29.73  -95.82]]\n",
            "\n",
            "[[ -37.23    7.65  -70.35 ...   -8.22  -57.81  -58.47]\n",
            " [ -54.39  -36.39   67.41 ...   34.02  -40.8    49.44]\n",
            " [ 172.41   10.89  -56.58 ...  -96.66   10.35 -163.83]\n",
            " ...\n",
            " [  57.24  -19.68  112.17 ...  -16.5   -68.43   47.1 ]\n",
            " [-108.75    2.31  -37.53 ...  -29.97   65.16   41.7 ]\n",
            " [   9.     21.21   43.56 ...   -8.97  -29.73  -95.82]]\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}